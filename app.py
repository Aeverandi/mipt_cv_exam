import streamlit as st
import os
from pathlib import Path
import datetime
import io
from modules.logs import safe_logger
from modules.ml import get_cached_models, detect_single_frame, generate_tab_internal, train_tab_internal
import cv2
import numpy as np
import tempfile
from PIL import Image
import imageio

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="CV Exam Project",
    page_icon="üé≠",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === –ö–≠–®–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ß–ï–†–ï–ó STREAMLIT ===
@st.cache_resource
def load_models_with_cache():
    """–§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è Streamlit –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    yolo, sd, status = get_cached_models()
    return yolo, sd, status

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
with st.spinner("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–≤–ø–µ—Ä–≤—ã–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)..."):
    yolo_model, sd_model, load_status = load_models_with_cache()

# === –ì–õ–ê–í–ù–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ===
def main_page():
    st.title("üé≠ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∞–∫—Ç—ë—Ä–æ–≤")
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    with st.expander("üîß –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π", expanded=True):
        if load_status["yolo_loaded"]:
            st.success("‚úÖ YOLO –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        else:
            st.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO")
        
        if load_status["sd_loaded"]:
            device = load_status["device"].upper()
            st.success(f"‚úÖ Stable Diffusion –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({device})")
            
            if device == "CPU":
                if load_status["accelerate_available"]:
                    st.success("‚úÖ CPU offload –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ accelerate")
                else:
                    st.warning("‚ö†Ô∏è CPU offload –æ—Ç–∫–ª—é—á–µ–Ω (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'accelerate' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞)")
                st.info("‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –±–∞–∑–æ–≤—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: attention slicing")
        else:
            st.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Stable Diffusion")
            if load_status["errors"]:
                for error in load_status["errors"]:
                    st.caption(f"‚Ä¢ {error}")
        
        if not load_status["accelerate_available"] and load_status["device"] == "cpu":
            st.info("""
            üí° –°–æ–≤–µ—Ç –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ CPU:
            –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É accelerate: `pip install accelerate==1.12.0`
            –≠—Ç–æ —É—Å–∫–æ—Ä–∏—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ 1.5-2 —Ä–∞–∑–∞
            """)

# === –†–ï–ñ–ò–ú –î–ï–¢–ï–ö–¶–ò–ò ===
def detection_page():
    logger = safe_logger
    st.header("üîç –î–µ—Ç–µ–∫—Ü–∏—è –∞–∫—Ç—ë—Ä–æ–≤")
    
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª", type=["jpg", "jpeg", "png", "gif", "mp4", "mov", "avi"])
    
    if uploaded_file is not None:
        file_name = uploaded_file.name
        file_size = uploaded_file.size
        is_video = file_name.lower().endswith((".mp4", ".mov", ".avi"))
        
        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é"):
            # === –ü–†–û–ì–†–ï–°–°–ë–ê–†–´ - –°–û–ó–î–ê–ï–ú –î–û –í–´–ó–û–í–ê ML ===
            progress_bar = st.progress(0)
            status_text = st.empty()
            result_container = st.container()
            
            try:
                # === –û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ===
                if not is_video:
                    status_text.text("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
                    progress_bar.progress(20)
                    
                    image = Image.open(io.BytesIO(uploaded_file.getvalue())).convert("RGB")
                    img_array = np.array(image)
                    img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                    
                    status_text.text("–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤...")
                    progress_bar.progress(50)
                    
                    results = yolo_model(img_bgr)
                    
                    # –°–±–æ—Ä –∞–∫—Ç—ë—Ä–æ–≤
                    detected_actors = []
                    for result_box in results[0].boxes:
                        class_id = int(result_box.cls[0])
                        actor_name = yolo_model.names[class_id]
                        if actor_name not in detected_actors:
                            detected_actors.append(actor_name)
                    
                    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è
                    annotated_frame = results[0].plot()
                    annotated_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                    annotated_image = Image.fromarray(annotated_rgb)
                    
                    progress_bar.progress(90)
                    status_text.text("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
                    
                    with result_container:
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏")
                        st.image(annotated_image, caption=f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–∏–∫—Ç–æ'}")
                    
                    progress_bar.progress(100)
                    status_text.text("–ì–æ—Ç–æ–≤–æ!")
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                    log_entry = f"–î–ï–¢–ï–ö–¶–ò–Ø | –§–∞–π–ª: {file_name} | –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}"
                    logger.info(log_entry)
                    st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥")
                
                # === –û–ë–†–ê–ë–û–¢–ö–ê –í–ò–î–ï–û ===
                else:
                    status_text.text("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ...")
                    progress_bar.progress(5)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è OpenCV
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_input:
                        tmp_input.write(uploaded_file.getvalue())
                        input_path = tmp_input.name
                    
                    cap = cv2.VideoCapture(input_path)
                    fps = max(1, int(cap.get(cv2.CAP_PROP_FPS)))  # –ó–∞—â–∏—Ç–∞ –æ—Ç fps=0
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    
                    # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    target_width = min(width, 640)
                    target_height = min(height, 480)
                    scale = min(target_width / width, target_height / height)
                    new_width = int(width * scale)
                    new_height = int(height * scale)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
                    processed_frames = []
                    detected_actors_set = set()
                    
                    status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: 0/{frame_count} –∫–∞–¥—Ä–æ–≤")
                    progress_bar.progress(10)
                    
                    for frame_idx in range(frame_count):
                        ret, frame = cap.read()
                        if not ret:
                            break
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞ —á–µ—Ä–µ–∑ ML —Ñ—É–Ω–∫—Ü–∏—é
                        frame_result = detect_single_frame(
                            yolo_model=yolo_model,
                            frame=frame,
                            scale=scale,
                            new_width=new_width,
                            new_height=new_height
                        )
                        
                        processed_frames.append(frame_result["annotated_frame"])
                        detected_actors_set.update(frame_result["actors"])
                        
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                        progress = 10 + int((frame_idx + 1) / frame_count * 80)
                        progress_bar.progress(min(progress, 95))
                        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {frame_idx + 1}/{frame_count} –∫–∞–¥—Ä–æ–≤")
                    
                    cap.release()
                    os.unlink(input_path)
                    
                    detected_actors = list(detected_actors_set)
                    
                    # === –°–û–ó–î–ê–ù–ò–ï –í–ò–î–ï–û –° IMAGEIO ===
                    status_text.text("–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ...")
                    progress_bar.progress(95)
                    
                    # –°–æ–∑–¥–∞—ë–º –±—É—Ñ–µ—Ä –≤ –ø–∞–º—è—Ç–∏
                    output_buffer = io.BytesIO()
                    
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –≤ –±—É—Ñ–µ—Ä
                    with imageio.get_writer(
                        output_buffer, 
                        format='mp4', 
                        fps=fps,
                        codec='libx264',  # H.264 - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤—Å–µ–º–∏ –±—Ä–∞—É–∑–µ—Ä–∞–º–∏
                        quality=7,        # –ö–∞—á–µ—Å—Ç–≤–æ 0-10
                        pixelformat='yuv420p'  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    ) as writer:
                        for frame in processed_frames:
                            writer.append_data(frame)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –±–∞–π—Ç—ã –≤–∏–¥–µ–æ
                    output_video_bytes = output_buffer.getvalue()
                    
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–µ–æ
                    with result_container:
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏")
                        st.video(output_video_bytes)
                        st.caption(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–∏–∫—Ç–æ'}")
                    
                    progress_bar.progress(100)
                    status_text.text("–ì–æ—Ç–æ–≤–æ!")
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                    log_entry = f"–î–ï–¢–ï–ö–¶–ò–Ø | –§–∞–π–ª: {file_name} | –¢–∏–ø: –≤–∏–¥–µ–æ | –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}"
                    logger.info(log_entry)
                    st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥")
            
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {str(e)}")
                logger.error(f"–î–ï–¢–ï–ö–¶–ò–Ø_–û–®–ò–ë–ö–ê | –§–∞–π–ª: {file_name} | –û—à–∏–±–∫–∞: {str(e)}")
    
    # === –°–ü–û–ô–õ–ï–† –° –õ–û–ì–ê–ú–ò ===
    with st.expander("üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"):
        log_content = logger.read_last_lines(n=15)
        st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞", log_content, height=300, key="detection_log_display")
        
        if logger.get_log_info()['exists']:
            with open(logger.log_path, 'rb') as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ª–æ–≥",
                    data=f.read(),
                    file_name=f"detection_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain"
                )

# === –†–ï–ñ–ò–ú –ì–ï–ù–ï–†–ê–¶–ò–ò ===
def generation_page():
    logger = safe_logger
    st.header("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    if sd_model is None:
        st.error("‚ùå Stable Diffusion –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        return
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç—ë—Ä–æ–≤
    embeddings_path = Path("models/sd_embeddings")
    if not embeddings_path.exists():
        embeddings_path = Path.cwd() / "models" / "sd_embeddings"
    
    actor_names = [f.stem for f in embeddings_path.glob("*.bin")] if embeddings_path.exists() else []
    
    if not actor_names:
        st.warning("‚ö†Ô∏è –ù–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –ø–∞–ø–∫–µ. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ–º–æ-–∞–∫—Ç—ë—Ä—ã.")
        actor_names = ["tom_hanks", "angelina_jolie", "brad_pitt"]
    
    selected_actor = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ç—ë—Ä–∞", actor_names, format_func=lambda x: x.replace("_", " ").title())
    
    # === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–û–ú–ü–¢–û–í –í APP.PY ===
    default_prompt = (
        f"a high-quality professional portrait photograph of {selected_actor.replace('_', ' ')}, "
        "looking directly at camera, natural expression, cinematic lighting, "
        "4k resolution, detailed skin texture, professional color grading"
    )
    default_negative_prompt = (
        "blurry, low quality, distorted face, extra limbs, disfigured, "
        "bad anatomy, duplicate, morbid, mutilated, out of frame, "
        "extra fingers, mutated hands, poorly drawn hands, poorly drawn face, "
        "text, watermark, signature, cartoon, drawing, anime, 3d render"
    )
    
    # === –°–ü–û–ô–õ–ï–† –° –ù–ê–°–¢–†–û–ô–ö–ê–ú–ò ===
    with st.expander("üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"):
        prompt = st.text_area("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç", value=default_prompt, height=100, key=f"prompt_{selected_actor}")
        negative_prompt = st.text_area("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç", value=default_negative_prompt, height=100, key=f"negative_prompt_{selected_actor}")
        num_steps = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", 15, 75, 35, key=f"steps_{selected_actor}")
        
        # –ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        is_cpu = sd_model.device.type == "cpu"
        resolution = st.selectbox(
            "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            [256, 384, 512],
            index=0 if is_cpu else 2,
            help="–î–ª—è CPU —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 256x256 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
            key=f"resolution_{selected_actor}"
        )
    
    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"):
        # === –ü–†–û–ì–†–ï–°–°–ë–ê–†–´ - –°–û–ó–î–ê–ï–ú –î–û –í–´–ó–û–í–ê ML ===
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_container = st.container()
        
        try:
            # Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            def update_progress(step, timestep, latents):
                progress = int(step / num_steps * 100)
                progress_bar.progress(min(progress, 99))
                status_text.text(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: —à–∞–≥ {step}/{num_steps}")
            
            result = generate_tab_internal(
                sd_model=sd_model,
                actor_name=selected_actor,
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_steps=num_steps,
                resolution=resolution,
                embeddings_dir=str(embeddings_path),
                progress_callback=update_progress,
                status_callback=lambda text: status_text.text(text)
            )
            
            if result["success"]:
                with result_container:
                    st.subheader(f"‚ú® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {selected_actor.replace('_', ' ')}")
                    st.image(result["generated_image"], caption=f"–†–∞–∑–º–µ—Ä: {resolution}x{resolution} px", width=256)
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    img_byte_arr = io.BytesIO()
                    result["generated_image"].save(img_byte_arr, format='PNG')
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                        data=img_byte_arr.getvalue(),
                        file_name=f"generated_{selected_actor}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                        mime="image/png",
                        type="primary"
                    )
                
                status_text.text("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                progress_bar.progress(100)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                log_entry = f"–ì–ï–ù–ï–†–ê–¶–ò–Ø | –ê–∫—Ç—ë—Ä: {selected_actor} | –ü—Ä–æ–º–ø—Ç: {prompt[:50]}..."
                logger.info(log_entry)
                st.success("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ª–æ–≥")
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {result['error']}")
                logger.error(f"–ì–ï–ù–ï–†–ê–¶–ò–Ø_–û–®–ò–ë–ö–ê | –ê–∫—Ç—ë—Ä: {selected_actor} | –û—à–∏–±–∫–∞: {result['error']}")
        
        except Exception as e:
            st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
            logger.error(f"–ì–ï–ù–ï–†–ê–¶–ò–Ø_–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø_–û–®–ò–ë–ö–ê | –ê–∫—Ç—ë—Ä: {selected_actor} | –û—à–∏–±–∫–∞: {str(e)}")
    
    # === –°–ü–û–ô–õ–ï–† –° –õ–û–ì–ê–ú–ò ===
    with st.expander("üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"):
        log_content = logger.read_last_lines(n=15)
        st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞", log_content, height=300, key="generation_log_display")
        
        if logger.get_log_info()['exists']:
            with open(logger.log_path, 'rb') as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ª–æ–≥",
                    data=f.read(),
                    file_name=f"generation_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain"
                )

# === –†–ï–ñ–ò–ú –î–û–û–ë–£–ß–ï–ù–ò–Ø ===
def training_page():
    logger = safe_logger
    st.header("üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    
    uploaded_zip = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP —Å —Ñ–æ—Ç–æ", type="zip")
    actor_name = st.text_input("–ò–º—è –∞–∫—Ç—ë—Ä–∞ (–ª–∞—Ç–∏–Ω–∏—Ü–µ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä: tom_hanks)")
    epochs = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö", 1, 50, 10)
    
    if st.button("–ù–∞—á–∞—Ç—å –¥–æ–æ–±—É—á–µ–Ω–∏–µ", disabled=(not uploaded_zip or not actor_name)):
        # === –ü–†–û–ì–†–ï–°–°–ë–ê–†–´ - –°–û–ó–î–ê–ï–ú –î–û –í–´–ó–û–í–ê ML ===
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_container = st.container()
        
        try:
            # Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            def update_progress(value, text):
                progress_bar.progress(min(value, 100))
                status_text.text(text)
            
            result = train_tab_internal(
                yolo_model=yolo_model,
                zip_data=uploaded_zip.getvalue() if uploaded_zip else None,
                actor_name=actor_name,
                epochs=epochs,
                progress_callback=update_progress
            )
            
            if result["success"]:
                st.success(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞ –Ω–∞ {result['images_processed']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö")
                st.metric("–ò—Ç–æ–≥–æ–≤—ã–π mAP", f"{result['metrics']['mAP']:.3f}")
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                log_entry = f"–î–û–û–ë–£–ß–ï–ù–ò–ï | –ê–∫—Ç—ë—Ä: {actor_name} | –≠–ø–æ—Ö–∏: {epochs} | mAP: {result['metrics']['mAP']:.3f}"
                logger.info(log_entry)
                st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥")
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è: {result['error']}")
                logger.error(f"–î–û–û–ë–£–ß–ï–ù–ò–ï_–û–®–ò–ë–ö–ê | –ê–∫—Ç—ë—Ä: {actor_name} | –û—à–∏–±–∫–∞: {result['error']}")
        
        except Exception as e:
            st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è: {str(e)}")
            logger.error(f"–î–û–û–ë–£–ß–ï–ù–ò–ï_–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø_–û–®–ò–ë–ö–ê | –ê–∫—Ç—ë—Ä: {actor_name} | –û—à–∏–±–∫–∞: {str(e)}")
    
    # === –°–ü–û–ô–õ–ï–† –° –õ–û–ì–ê–ú–ò ===
    with st.expander("üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"):
        log_content = logger.read_last_lines(n=15)
        st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞", log_content, height=300, key="training_log_display")
        
        if logger.get_log_info()['exists']:
            with open(logger.log_path, 'rb') as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ª–æ–≥",
                    data=f.read(),
                    file_name=f"training_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain"
                )

# === –ù–ê–í–ò–ì–ê–¶–ò–Ø ===
st.sidebar.title("üöÄ –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ: –≠–∫–∑–∞–º–µ–Ω")
mode = st.sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º",
    ["üè† –ì–ª–∞–≤–Ω–∞—è", "üëÅÔ∏è –î–µ—Ç–µ–∫—Ü–∏—è", "üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è", "üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ"],
    index=0
)

if mode == "üè† –ì–ª–∞–≤–Ω–∞—è":
    main_page()
elif mode == "üëÅÔ∏è –î–µ—Ç–µ–∫—Ü–∏—è":
    detection_page()
elif mode == "üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è":
    generation_page()
elif mode == "üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ":
    training_page()

# –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Å–∫—Ä—ã—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
with st.sidebar.expander("üîß –û—Ç–ª–∞–¥–∫–∞", expanded=False):
    st.caption(f"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {Path.cwd()}")
    st.caption(f"YOLO –º–æ–¥–µ–ª—å: {'–∑–∞–≥—Ä—É–∂–µ–Ω–∞' if yolo_model else '–Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")
    st.caption(f"SD –º–æ–¥–µ–ª—å: {'–∑–∞–≥—Ä—É–∂–µ–Ω–∞' if sd_model else '–Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")