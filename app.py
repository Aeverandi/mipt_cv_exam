import streamlit as st
import os
from pathlib import Path
import datetime
import io
import cv2
import numpy as np
import tempfile
from PIL import Image
import imageio

# –ò–∑–≤–∏–Ω–∏—Ç–µ, –≤—ã—á–ª–µ–Ω–∏–ª –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã - —Ç—è–∂–µ–ª–æ —Ä–∞–±–æ—Ç–∞–ª–æ—Å—å —Å –±–æ–ª–µ–µ —á–µ–º 1000 —Å—Ç—Ä–æ–∫–∞–º–∏ –∫–æ–¥–∞ —É–∂–µ...
from modules.logs import safe_logger
from modules.ml import get_cached_models, detect_single_frame, generate_tab_internal, detect_faces, prepare_yolo_dataset, train_yolo_model

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="CV Exam Project",
    page_icon="üé≠",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === –ö–≠–®–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô ===
@st.cache_resource
def load_models_with_cache():
    """–§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è Streamlit –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    yolo, sd, status = get_cached_models()
    return yolo, sd, status

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
with st.spinner("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–≤–ø–µ—Ä–≤—ã–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)..."):
    yolo_model, sd_model, load_status = load_models_with_cache()

# === –ì–õ–ê–í–ù–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ===
def main_page():
    st.title("üé≠ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∞–∫—Ç—ë—Ä–æ–≤")
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    with st.expander("üîß –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π", expanded=True):
        if load_status["yolo_loaded"]:
            st.success("‚úÖ YOLO –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        else:
            st.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO")
        
        if load_status["sd_loaded"]:
            device = load_status["device"].upper()
            st.success(f"‚úÖ Stable Diffusion –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({device})")
            
            if device == "CPU":
                if load_status["accelerate_available"]:
                    st.success("‚úÖ CPU offload –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ accelerate")
                else:
                    st.warning("‚ö†Ô∏è CPU offload –æ—Ç–∫–ª—é—á–µ–Ω (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'accelerate' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞)")
                st.info("‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –±–∞–∑–æ–≤—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: attention slicing")
        else:
            st.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Stable Diffusion")
            if load_status["errors"]:
                for error in load_status["errors"]:
                    st.caption(f"‚Ä¢ {error}")
        
        if not load_status["accelerate_available"] and load_status["device"] == "cpu":
            st.info("""
            üí° –°–æ–≤–µ—Ç –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ CPU:
            –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É accelerate: `pip install accelerate==1.12.0`
            –≠—Ç–æ —É—Å–∫–æ—Ä–∏—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ 1.5-2 —Ä–∞–∑–∞
            """)

# === –†–ï–ñ–ò–ú –î–ï–¢–ï–ö–¶–ò–ò ===
def detection_page():
    logger = safe_logger
    st.header("üîç –î–µ—Ç–µ–∫—Ü–∏—è –∞–∫—Ç—ë—Ä–æ–≤")
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (JPG, PNG, GIF) –∏–ª–∏ –≤–∏–¥–µ–æ (MP4, MOV, AVI) –¥–æ 25 –ú–ë –∏ –¥–æ 10 —Å–µ–∫—É–Ω–¥.")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª", type=["jpg", "jpeg", "png", "gif", "mp4", "mov", "avi"])
    
    if uploaded_file is not None:
        file_name = uploaded_file.name
        file_size = uploaded_file.size
        is_video = file_name.lower().endswith((".mp4", ".mov", ".avi"))
        
        if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é"):
            # === –ü–†–û–ì–†–ï–°–°–ë–ê–†–´ - –°–û–ó–î–ê–ï–ú –î–û –í–´–ó–û–í–ê ML ===
            progress_bar = st.progress(0)
            status_text = st.empty()
            result_container = st.container()
            
            try:
                # === –û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ===
                if not is_video:
                    status_text.text("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
                    progress_bar.progress(20)
                    
                    image = Image.open(io.BytesIO(uploaded_file.getvalue())).convert("RGB")
                    img_array = np.array(image)
                    img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                    
                    status_text.text("–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤...")
                    progress_bar.progress(50)
                    
                    results = yolo_model(img_bgr)
                    
                    # –°–±–æ—Ä –∞–∫—Ç—ë—Ä–æ–≤
                    detected_actors = []
                    for result_box in results[0].boxes:
                        class_id = int(result_box.cls[0])
                        actor_name = yolo_model.names[class_id]
                        if actor_name not in detected_actors:
                            detected_actors.append(actor_name)
                    
                    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è
                    annotated_frame = results[0].plot()
                    annotated_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                    annotated_image = Image.fromarray(annotated_rgb)
                    
                    progress_bar.progress(90)
                    status_text.text("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
                    
                    with result_container:
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏")
                        st.image(annotated_image, caption=f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–∏–∫—Ç–æ'}")
                    
                    progress_bar.progress(100)
                    status_text.text("–ì–æ—Ç–æ–≤–æ!")
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                    log_entry = f"–î–ï–¢–ï–ö–¶–ò–Ø | –§–∞–π–ª: {file_name} | –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}"
                    logger.info(log_entry)
                    st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥")
                
                # === –û–ë–†–ê–ë–û–¢–ö–ê –í–ò–î–ï–û ===
                else:
                    status_text.text("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ...")
                    progress_bar.progress(5)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è OpenCV
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_input:
                        tmp_input.write(uploaded_file.getvalue())
                        input_path = tmp_input.name
                    
                    cap = cv2.VideoCapture(input_path)
                    fps = max(1, int(cap.get(cv2.CAP_PROP_FPS)))  # –ó–∞—â–∏—Ç–∞ –æ—Ç fps=0
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    
                    # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    target_width = min(width, 640)
                    target_height = min(height, 480)
                    scale = min(target_width / width, target_height / height)
                    new_width = int(width * scale)
                    new_height = int(height * scale)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
                    processed_frames = []
                    detected_actors_set = set()
                    
                    status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: 0/{frame_count} –∫–∞–¥—Ä–æ–≤")
                    progress_bar.progress(10)
                    
                    for frame_idx in range(frame_count):
                        ret, frame = cap.read()
                        if not ret:
                            break
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞ —á–µ—Ä–µ–∑ ML —Ñ—É–Ω–∫—Ü–∏—é
                        frame_result = detect_single_frame(
                            yolo_model=yolo_model,
                            frame=frame,
                            scale=scale,
                            new_width=new_width,
                            new_height=new_height
                        )
                        
                        processed_frames.append(frame_result["annotated_frame"])
                        detected_actors_set.update(frame_result["actors"])
                        
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                        progress = 10 + int((frame_idx + 1) / frame_count * 80)
                        progress_bar.progress(min(progress, 95))
                        status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {frame_idx + 1}/{frame_count} –∫–∞–¥—Ä–æ–≤")
                    
                    cap.release()
                    os.unlink(input_path)
                    
                    detected_actors = list(detected_actors_set)
                    
                    # === –°–û–ó–î–ê–ù–ò–ï –í–ò–î–ï–û –° IMAGEIO ===
                    status_text.text("–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ...")
                    progress_bar.progress(95)
                    
                    # –°–æ–∑–¥–∞—ë–º –±—É—Ñ–µ—Ä –≤ –ø–∞–º—è—Ç–∏
                    output_buffer = io.BytesIO()
                    
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –≤ –±—É—Ñ–µ—Ä
                    with imageio.get_writer(
                        output_buffer, 
                        format='mp4', 
                        fps=fps,
                        codec='libx264',  # H.264 - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤—Å–µ–º–∏ –±—Ä–∞—É–∑–µ—Ä–∞–º–∏
                        quality=7,        # –ö–∞—á–µ—Å—Ç–≤–æ 0-10
                        pixelformat='yuv420p'  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    ) as writer:
                        for frame in processed_frames:
                            writer.append_data(frame)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –±–∞–π—Ç—ã –≤–∏–¥–µ–æ
                    output_video_bytes = output_buffer.getvalue()
                    
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–µ–æ
                    with result_container:
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏")
                        st.video(output_video_bytes)
                        st.caption(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–∏–∫—Ç–æ'}")
                    
                    progress_bar.progress(100)
                    status_text.text("–ì–æ—Ç–æ–≤–æ!")
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                    log_entry = f"–î–ï–¢–ï–ö–¶–ò–Ø | –§–∞–π–ª: {file_name} | –¢–∏–ø: –≤–∏–¥–µ–æ | –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: {', '.join(detected_actors) if detected_actors else '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}"
                    logger.info(log_entry)
                    st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥")
            
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {str(e)}")
                logger.error(f"–î–ï–¢–ï–ö–¶–ò–Ø_–û–®–ò–ë–ö–ê | –§–∞–π–ª: {file_name} | –û—à–∏–±–∫–∞: {str(e)}")
    
    # === –°–ü–û–ô–õ–ï–† –° –õ–û–ì–ê–ú–ò ===
    with st.expander("üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"):
        log_content = logger.read_last_lines(n=15)
        st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞", log_content, height=300, key="detection_log_display")
        
        if logger.get_log_info()['exists']:
            with open(logger.log_path, 'rb') as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ª–æ–≥",
                    data=f.read(),
                    file_name=f"detection_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain"
                )

# === –†–ï–ñ–ò–ú –ì–ï–ù–ï–†–ê–¶–ò–ò ===
def generation_page():
    logger = safe_logger
    st.header("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    st.write("–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ç—ë—Ä–∞ –∏–∑ —Å–ø–∏—Å–∫–∞, —á—Ç–æ–±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    if sd_model is None:
        st.error("‚ùå Stable Diffusion –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        return
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç—ë—Ä–æ–≤
    embeddings_path = Path("models/sd_embeddings")
    if not embeddings_path.exists():
        embeddings_path = Path.cwd() / "models" / "sd_embeddings"
    
    actor_names = [f.stem for f in embeddings_path.glob("*.bin")] if embeddings_path.exists() else []
    
    if not actor_names:
        st.warning("‚ö†Ô∏è –ù–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –ø–∞–ø–∫–µ. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ–º–æ-–∞–∫—Ç—ë—Ä—ã.")
        actor_names = ["tom_hanks", "angelina_jolie", "brad_pitt"]
    
    selected_actor = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞–∫—Ç—ë—Ä–∞", actor_names, format_func=lambda x: x.replace("_", " ").title())
    
    # === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–û–ú–ü–¢–û–í –í APP.PY ===
    default_prompt = (
        f"a high-quality professional portrait photograph of {selected_actor.replace('_', ' ')}, "
        "looking directly at camera, natural expression, cinematic lighting, "
        "4k resolution, detailed skin texture, professional color grading"
    )
    default_negative_prompt = (
        "blurry, low quality, distorted face, extra limbs, disfigured, "
        "bad anatomy, duplicate, morbid, mutilated, out of frame, "
        "extra fingers, mutated hands, poorly drawn hands, poorly drawn face, "
        "text, watermark, signature, cartoon, drawing, anime, 3d render"
    )
    
    # === –°–ü–û–ô–õ–ï–† –° –ù–ê–°–¢–†–û–ô–ö–ê–ú–ò ===
    with st.expander("üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"):
        prompt = st.text_area("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç", value=default_prompt, height=100, key=f"prompt_{selected_actor}")
        negative_prompt = st.text_area("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç", value=default_negative_prompt, height=100, key=f"negative_prompt_{selected_actor}")
        num_steps = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", 15, 75, 35, key=f"steps_{selected_actor}")
        
        # –ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        is_cpu = sd_model.device.type == "cpu"
        resolution = st.selectbox(
            "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            [256, 384, 512],
            index=0 if is_cpu else 2,
            help="–î–ª—è CPU —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 256x256 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
            key=f"resolution_{selected_actor}"
        )
    
    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"):
        # === –ü–†–û–ì–†–ï–°–°–ë–ê–†–´ - –°–û–ó–î–ê–ï–ú –î–û –í–´–ó–û–í–ê ML ===
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_container = st.container()
        
        try:
            # Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            def update_progress(step, timestep, latents):
                progress = int(step / num_steps * 100)
                progress_bar.progress(min(progress, 99))
                status_text.text(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: —à–∞–≥ {step}/{num_steps}")
            
            result = generate_tab_internal(
                sd_model=sd_model,
                actor_name=selected_actor,
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_steps=num_steps,
                resolution=resolution,
                embeddings_dir=str(embeddings_path),
                progress_callback=update_progress,
                status_callback=lambda text: status_text.text(text)
            )
            
            if result["success"]:
                with result_container:
                    st.subheader(f"‚ú® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {selected_actor.replace('_', ' ')}")
                    st.image(result["generated_image"], caption=f"–†–∞–∑–º–µ—Ä: {resolution}x{resolution} px", width=256)
                    
                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    img_byte_arr = io.BytesIO()
                    result["generated_image"].save(img_byte_arr, format='PNG')
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                        data=img_byte_arr.getvalue(),
                        file_name=f"generated_{selected_actor}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                        mime="image/png",
                        type="primary"
                    )
                
                status_text.text("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                progress_bar.progress(100)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                log_entry = f"–ì–ï–ù–ï–†–ê–¶–ò–Ø | –ê–∫—Ç—ë—Ä: {selected_actor} | –ü—Ä–æ–º–ø—Ç: {prompt[:50]}..."
                logger.info(log_entry)
                st.success("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ª–æ–≥")
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {result['error']}")
                logger.error(f"–ì–ï–ù–ï–†–ê–¶–ò–Ø_–û–®–ò–ë–ö–ê | –ê–∫—Ç—ë—Ä: {selected_actor} | –û—à–∏–±–∫–∞: {result['error']}")
        
        except Exception as e:
            st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
            logger.error(f"–ì–ï–ù–ï–†–ê–¶–ò–Ø_–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø_–û–®–ò–ë–ö–ê | –ê–∫—Ç—ë—Ä: {selected_actor} | –û—à–∏–±–∫–∞: {str(e)}")
    
    # === –°–ü–û–ô–õ–ï–† –° –õ–û–ì–ê–ú–ò ===
    with st.expander("üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"):
        log_content = logger.read_last_lines(n=15)
        st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞", log_content, height=300, key="generation_log_display")
        
        if logger.get_log_info()['exists']:
            with open(logger.log_path, 'rb') as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ª–æ–≥",
                    data=f.read(),
                    file_name=f"generation_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain"
                )


# === –†–ï–ñ–ò–ú –î–û–û–ë–£–ß–ï–ù–ò–Ø (–î–í–ê –≠–¢–ê–ü–ê) ===
# === –†–ï–ñ–ò–ú –î–û–û–ë–£–ß–ï–ù–ò–Ø (–î–í–ê –≠–¢–ê–ü–ê) ===
def training_page():
    logger = safe_logger
    st.header("üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")

    # === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–û–°–¢–û–Ø–ù–ò–ô ===
    if "training_stage" not in st.session_state:
        st.session_state.training_stage = "upload"  # upload, annotate, train

    if "annotated_images" not in st.session_state:
        st.session_state.annotated_images = []

    if "accepted_images" not in st.session_state:
        st.session_state.accepted_images = []

    if "current_image_idx" not in st.session_state:
        st.session_state.current_image_idx = 0

    # === –≠–¢–ê–ü 1: –ó–ê–ì–†–£–ó–ö–ê –ê–†–•–ò–í–ê ===
    if st.session_state.training_stage == "upload":
        st.subheader("üìÅ –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP-–∞—Ä—Ö–∏–≤ —Å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ –æ–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")

        uploaded_zip = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP —Å —Ñ–æ—Ç–æ", type="zip", key="zip_uploader")
        actor_name = st.text_input(
            "–ò–º—è –∞–∫—Ç—ë—Ä–∞ (–ª–∞—Ç–∏–Ω–∏—Ü–µ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä: ben_afflek)",
            placeholder="ben_afflek",
            key="actor_name_input"
        )

        # === –ü–†–û–í–ï–†–ö–ê –ì–û–¢–û–í–ù–û–°–¢–ò ===
        is_ready = uploaded_zip is not None and bool(actor_name.strip())

        if st.button("üîç –í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É", disabled=not is_ready, type="primary", use_container_width=True):
            with st.spinner("üîÑ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü..."):
                try:
                    if uploaded_zip is None:
                        st.error("–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
                        return

                    if not actor_name.strip():
                        st.error("–ò–º—è –∞–∫—Ç—ë—Ä–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
                        return

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 50 –ú–ë –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
                    if uploaded_zip.size > 50 * 1024 * 1024:
                        st.error(
                            f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 50 –ú–ë. –í–∞—à —Ñ–∞–π–ª: {uploaded_zip.size / (1024 * 1024):.1f} –ú–ë")
                        logger.warning(
                            f"–î–û–û–ë–£–ß–ï–ù–ò–ï | –û—Ç–∫–ª–æ–Ω—ë–Ω –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {uploaded_zip.name} ({uploaded_zip.size // 1024} –ö–ë)")
                        return

                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    with tempfile.TemporaryDirectory() as tmp_dir:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º ZIP —Ñ–∞–π–ª
                        zip_path = os.path.join(tmp_dir, uploaded_zip.name)
                        with open(zip_path, "wb") as f:
                            f.write(uploaded_zip.getvalue())

                        # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞
                        import zipfile
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(tmp_dir)

                        # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                        image_files = []
                        valid_extensions = {".jpg", ".jpeg", ".png"}
                        for root, _, files in os.walk(tmp_dir):
                            for f in files:
                                if Path(f).suffix.lower() in valid_extensions:
                                    image_files.append(os.path.join(root, f))

                        if not image_files:
                            st.error("–í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (JPG/PNG)!")
                            logger.warning("–î–û–û–ë–£–ß–ï–ù–ò–ï | –í –∞—Ä—Ö–∏–≤–µ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                            return

                        st.info(f"üìÇ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")

                        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
                        annotated_images = []
                        from PIL import Image
                        import time

                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        for idx, img_path in enumerate(image_files):
                            try:
                                # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                                img = Image.open(img_path).convert("RGB")

                                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                                progress = int((idx + 1) / len(image_files) * 100)
                                progress_bar.progress(progress)
                                status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {idx + 1}/{len(image_files)}")

                                # === –ò–°–ü–û–õ–¨–ó–£–ï–ú –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–£–Æ –§–£–ù–ö–¶–ò–Æ –î–ï–¢–ï–ö–¶–ò–ò ===
                                start_time = time.time()
                                faces = detect_faces(img)
                                detection_time = time.time() - start_time

                                logger.info(
                                    f"ML | –î–µ—Ç–µ–∫—Ü–∏—è –¥–ª—è {os.path.basename(img_path)}: {len(faces)} –ª–∏—Ü, –≤—Ä–µ–º—è: {detection_time:.2f}—Å")

                                # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π
                                for face in faces:
                                    bbox = face["box"]  # [x, y, width, height]

                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ bbox –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                    img_width, img_height = img.size
                                    x, y, w, h = bbox
                                    if x < 0 or y < 0 or x + w > img_width or y + h > img_height:
                                        continue

                                    annotated_images.append({
                                        "original_path": img_path,
                                        "image": img.copy(),
                                        "bbox": bbox,
                                        "method_used": face.get("method", "unknown"),
                                        "confidence": face.get("confidence", 1.0),
                                        "accepted": True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏–Ω–∏–º–∞–µ–º
                                    })
                            except Exception as e:
                                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_path}: {str(e)}")
                                continue

                        if not annotated_images:
                            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–∏—Ü–∞ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏!")
                            logger.error("–î–û–û–ë–£–ß–ï–ù–ò–ï | –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ª–∏—Ü –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö")
                            return

                        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–æ–¥–Ω–æ –ª–∏—Ü–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
                        unique_images = {}
                        for item in annotated_images:
                            img_path = item["original_path"]
                            if img_path not in unique_images:
                                unique_images[img_path] = item
                            else:
                                # –û—Å—Ç–∞–≤–ª—è–µ–º –ª–∏—Ü–æ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º confidence
                                if item.get("confidence", 0) > unique_images[img_path].get("confidence", 0):
                                    unique_images[img_path] = item

                        annotated_images = list(unique_images.values())

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                        st.session_state.annotated_images = annotated_images
                        st.session_state.accepted_images = list(annotated_images)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏–Ω–∏–º–∞–µ–º –≤—Å–µ
                        st.session_state.actor_name = actor_name.strip()
                        st.session_state.current_image_idx = 0
                        st.session_state.training_stage = "annotate"

                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
                        methods_used = set(img["method_used"] for img in annotated_images)
                        total_images = len(image_files)
                        detected_images = len(annotated_images)
                        detection_rate = detected_images / total_images * 100

                        st.success(
                            f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü –Ω–∞ {detected_images} –∏–∑ {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({detection_rate:.1f}%)")
                        st.info(f"‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –º–µ—Ç–æ–¥ –¥–µ—Ç–µ–∫—Ü–∏–∏: {', '.join(methods_used)}")

                        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä–∞–∑–º–µ—Ç–∫–∏
                        time.sleep(1)
                        st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun

                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏: {str(e)}")
                    logger.error(f"–î–û–û–ë–£–ß–ï–ù–ò–ï_–û–®–ò–ë–ö–ê | –≠—Ç–∞–ø: —Ä–∞–∑–º–µ—Ç–∫–∞ | –û—à–∏–±–∫–∞: {str(e)}")

    # === –≠–¢–ê–ü 2: –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–¢–ö–ò ===
    if st.session_state.training_stage == "annotate":
        st.subheader("‚úÖ –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏")
        st.write("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ç–∫—É –Ω–∞ –∫–∞–∂–¥–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. –û—Ç–∫–ª–æ–Ω–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π.")

        if not st.session_state.annotated_images:
            st.warning("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏. –í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –ø–µ—Ä–≤–æ–º—É —à–∞–≥—É.")
            if st.button("‚Ü©Ô∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –∑–∞–≥—Ä—É–∑–∫–µ", use_container_width=True):
                st.session_state.training_stage = "upload"
                st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun
            return

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_images = len(st.session_state.annotated_images)
        accepted_count = sum(1 for img in st.session_state.annotated_images if img.get("accepted", False))

        col1, col2, col3 = st.columns(3)
        col1.metric("–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", total_images)
        col2.metric("–ü—Ä–∏–Ω—è—Ç–æ", accepted_count)
        col3.metric("–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∏–Ω—è—Ç—ã—Ö", f"{accepted_count / total_images * 100:.0f}%")

        st.progress(accepted_count / total_images if total_images > 0 else 0)

        # –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        if total_images > 1:
            col1, col2, col3 = st.columns([1, 2, 1])
            with col1:
                if st.button("‚¨ÖÔ∏è –ü—Ä–µ–¥—ã–¥—É—â–µ–µ", disabled=(st.session_state.current_image_idx <= 0),
                             use_container_width=True):
                    st.session_state.current_image_idx = max(0, st.session_state.current_image_idx - 1)
                    st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun
            with col2:
                st.markdown(f"### –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {st.session_state.current_image_idx + 1} –∏–∑ {total_images}")
            with col3:
                if st.button("–°–ª–µ–¥—É—é—â–µ–µ ‚û°Ô∏è", disabled=(st.session_state.current_image_idx >= total_images - 1),
                             use_container_width=True):
                    st.session_state.current_image_idx = min(total_images - 1, st.session_state.current_image_idx + 1)
                    st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π
        current_item = st.session_state.annotated_images[st.session_state.current_image_idx]
        img = current_item["image"].copy()
        bbox = current_item["bbox"]

        # –†–∏—Å—É–µ–º bbox –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        from PIL import ImageDraw
        draw = ImageDraw.Draw(img)
        x, y, w, h = bbox
        draw.rectangle([x, y, x + w, y + h], outline="red", width=3)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        confidence = current_item.get("confidence", 1.0)
        method = current_item.get("method_used", "unknown")
        draw.text((x, y - 25), f"–õ–∏—Ü–æ ({method.upper()})", fill="red")
        if method == "mtcnn_gpu":
            draw.text((x, y - 10), f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}", fill="red")

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        st.image(img, caption=f"–†–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è: {st.session_state.actor_name}",
                 width='content')  # –ó–ê–ú–ï–ù–ê use_column_width –ù–ê width=None

        # –ö–Ω–æ–ø–∫–∏ –ø—Ä–∏–Ω—è—Ç–∏—è/–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
        current_accepted = current_item.get("accepted", True)

        col1, col2 = st.columns(2)
        with col1:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∫–Ω–æ–ø–∫–∞ –∞–∫—Ç–∏–≤–Ω–∞, –∫–æ–≥–¥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ù–ï –ø—Ä–∏–Ω—è—Ç–æ
            if st.button("‚úÖ –ü—Ä–∏–Ω—è—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É", type="primary", use_container_width=True, disabled=current_accepted):
                current_item["accepted"] = True
                st.success("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun

        with col2:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∫–Ω–æ–ø–∫–∞ –∞–∫—Ç–∏–≤–Ω–∞, –∫–æ–≥–¥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ
            if st.button("‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É", use_container_width=True, disabled=not current_accepted):
                current_item["accepted"] = False
                st.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–æ –∏–∑ –æ–±—É—á–µ–Ω–∏—è")
                st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
        status_emoji = "‚úÖ" if current_accepted else "‚ùå"
        status_text = "–ø—Ä–∏–Ω—è—Ç–æ" if current_accepted else "–æ—Ç–∫–ª–æ–Ω–µ–Ω–æ"
        st.markdown(f"### –°—Ç–∞—Ç—É—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {status_emoji} {status_text}")

        # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        with st.expander("üìä –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º"):
            accepted_images = [img for img in st.session_state.annotated_images if img.get("accepted", False)]
            st.write(f"**–ü—Ä–∏–Ω—è—Ç–æ:** {len(accepted_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            st.write(f"**–û—Ç–∫–ª–æ–Ω–µ–Ω–æ:** {total_images - len(accepted_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

            if accepted_images:
                methods_count = {}
                for img in accepted_images:
                    method = img.get("method_used", "unknown")
                    methods_count[method] = methods_count.get(method, 0) + 1

                st.write("**–ú–µ—Ç–æ–¥—ã –¥–µ—Ç–µ–∫—Ü–∏–∏:**")
                for method, count in methods_count.items():
                    st.write(f"- {method.upper()}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

        # –ö–Ω–æ–ø–∫–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚Ü©Ô∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –∑–∞–≥—Ä—É–∑–∫–µ", use_container_width=True):
                st.session_state.training_stage = "upload"
                st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun
        with col2:
            min_images = 3
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ", disabled=(accepted_count < min_images), use_container_width=True):
                if accepted_count < min_images:
                    st.warning(f"–î–ª—è –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {min_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π!")
                else:
                    st.session_state.training_stage = "train"
                    st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun

    # === –≠–¢–ê–ü 3: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ===
    if st.session_state.training_stage == "train":
        st.subheader("üöÄ –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
        st.write(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç—ë—Ä–∞: {st.session_state.actor_name}")

        accepted_images = [img for img in st.session_state.annotated_images if img.get("accepted", False)]
        accepted_count = len(accepted_images)

        if accepted_count == 0:
            st.error("–ù–µ—Ç –ø—Ä–∏–Ω—è—Ç—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
            if st.button("‚Ü©Ô∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä–∞–∑–º–µ—Ç–∫–∏", use_container_width=True):
                st.session_state.training_stage = "annotate"
                st.rerun()  # –ó–ê–ú–ï–ù–ê experimental_rerun –ù–ê rerun
            return

        st.info(f"‚úÖ **–ü—Ä–∏–Ω—è—Ç–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:** {accepted_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

        epochs = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è", min_value=5, max_value=100, value=20, key="epochs")
        batch_size_options = [4, 8, 16, 32]
        batch_size = st.selectbox("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞", batch_size_options, index=1, key="batch_size")

        st.caption("""
        üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
        - –î–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (3-10) –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ 15-25 —ç–ø–æ—Ö
        - –î–ª—è –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (>10) –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ 30-50 —ç–ø–æ—Ö
        - –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ 8 –æ–ø—Ç–∏–º–∞–ª–µ–Ω –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ GPU
        """)

        if st.button("üî• –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", type="primary", use_container_width=True):
            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∏ —Å—Ç–∞—Ç—É—Å
            progress_bar = st.progress(0)
            status_text = st.empty()
            result_container = st.container()

            try:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
                status_text.text("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
                progress_bar.progress(5)

                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                dataset_dir = Path.cwd() / "temp_training_data"
                dataset_dir.mkdir(parents=True, exist_ok=True)

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO
                images_dir, labels_dir, data_yaml_path = prepare_yolo_dataset(
                    accepted_images,
                    st.session_state.actor_name,
                    base_dir=dataset_dir
                )

                status_text.text(f"–î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω: {accepted_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                progress_bar.progress(15)

                # Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                def progress_callback(percent, text):
                    progress_bar.progress(percent)
                    status_text.text(text)

                # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                status_text.text("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
                training_result = train_yolo_model(
                    data_yaml_path=data_yaml_path,
                    epochs=epochs,
                    batch_size=batch_size,
                    progress_callback=progress_callback,
                    status_callback=lambda text: status_text.text(text)
                )

                if training_result["success"]:
                    progress_bar.progress(100)
                    status_text.text("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    with result_container:
                        st.success("üéâ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –¥–æ–æ–±—É—á–µ–Ω–∞!")

                        # –ú–µ—Ç—Ä–∏–∫–∏
                        metrics = training_result["metrics"]
                        col1, col2, col3, col4 = st.columns(4)

                        with col1:
                            st.metric("Precision", f"{metrics['precision']:.3f}")
                            st.caption("–¢–æ—á–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏")

                        with col2:
                            st.metric("Recall", f"{metrics['recall']:.3f}")
                            st.caption("–ü–æ–ª–Ω–æ—Ç–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")

                        with col3:
                            st.metric("mAP@0.5", f"{metrics['map50']:.3f}")
                            st.caption("–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ IoU=0.5")

                        with col4:
                            st.metric("mAP@0.5-0.95", f"{metrics['map50_95']:.3f}")
                            st.caption("–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ IoU=0.5-0.95")

                        # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è
                        results_path = metrics.get("results_path")
                        if results_path and os.path.exists(results_path):
                            st.subheader("üìä –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
                            st.image(results_path, caption="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è YOLO",
                                     width='content')  # –ó–ê–ú–ï–ù–ê use_column_width –ù–ê width=None

                        # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
                        status_text.text("–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
                        from ultralytics import YOLO
                        global yolo_model

                        new_model_path = training_result["model_path"]
                        try:
                            yolo_model = YOLO(new_model_path)
                            st.success("‚úÖ –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ –¥–µ—Ç–µ–∫—Ü–∏–∏!")
                        except Exception as e:
                            logger.error(f"–î–û–û–ë–£–ß–ï–ù–ò–ï | –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {str(e)}")
                            st.warning(
                                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π.")

                        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                        log_entry = (
                            f"–î–û–û–ë–£–ß–ï–ù–ò–ï_–£–°–ü–ï–®–ù–û | –ê–∫—Ç—ë—Ä: {st.session_state.actor_name} | "
                            f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {accepted_count} | –≠–ø–æ—Ö–∏: {epochs} | "
                            f"Precision: {metrics['precision']:.3f} | Recall: {metrics['recall']:.3f} | "
                            f"mAP@0.5: {metrics['map50']:.3f} | mAP@0.5-0.95: {metrics['map50_95']:.3f}"
                        )
                        logger.info(log_entry)


                else:
                    raise Exception(training_result["error"])

            except Exception as e:
                progress_bar.progress(0)
                status_text.text("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è!")
                st.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")
                logger.error(
                    f"–î–û–û–ë–£–ß–ï–ù–ò–ï_–û–®–ò–ë–ö–ê | –≠—Ç–∞–ø: –æ–±—É—á–µ–Ω–∏–µ | –ê–∫—Ç—ë—Ä: {st.session_state.actor_name} | –û—à–∏–±–∫–∞: {str(e)}")

    # === –°–ü–û–ô–õ–ï–† –° –õ–û–ì–ê–ú–ò ===
    with st.expander("üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞"):
        log_content = logger.read_last_lines(n=15)
        st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞", log_content, height=300, key="training_log")

        if logger.get_log_info()['exists']:
            with open(logger.log_path, 'rb') as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ª–æ–≥",
                    data=f.read(),
                    file_name=f"training_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
                    mime="text/plain",
                    use_container_width=True
                )

# === –ù–ê–í–ò–ì–ê–¶–ò–Ø ===
st.sidebar.title("üöÄ –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ: –≠–∫–∑–∞–º–µ–Ω")
mode = st.sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º",
    ["üè† –ì–ª–∞–≤–Ω–∞—è", "üëÅÔ∏è –î–µ—Ç–µ–∫—Ü–∏—è", "üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è", "üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ"],
    index=0
)

if mode == "üè† –ì–ª–∞–≤–Ω–∞—è":
    main_page()
elif mode == "üëÅÔ∏è –î–µ—Ç–µ–∫—Ü–∏—è":
    detection_page()
elif mode == "üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è":
    generation_page()
elif mode == "üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ":
    training_page()

# –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Å–∫—Ä—ã—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
with st.sidebar.expander("üîß –û—Ç–ª–∞–¥–∫–∞", expanded=False):
    st.caption(f"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {Path.cwd()}")
    st.caption(f"YOLO –º–æ–¥–µ–ª—å: {f'–∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({yolo_model.ckpt_path})' if yolo_model else '–Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")
    st.caption(f"SD –º–æ–¥–µ–ª—å: {f'–∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({sd_model.config._name_or_path})' if sd_model else '–Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")
